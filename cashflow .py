# -*- coding: utf-8 -*-
"""Cashflow.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wHqUuPsXRsOe6dIkWE9IiYfh40XPBklx
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from xgboost import XGBRegressor

warnings.filterwarnings('ignore')
sns.set(style="whitegrid")

data = pd.read_csv('Cashflow_dataset.csv')
print("First 5 rows:")
display(data.head())

# Observation: Dataset preview shows numeric and categorical company data.

print("Dataset Shape:", data.shape)

# Observation: Confirms total rows and columns in the dataset.

print("\nDataset Info:")
data.info()

# Observation: Displays column datatypes and non-null counts.

print("\nStatistical Summary of Numeric Columns:")
display(data.describe().T)

# Observation: Provides descriptive statistics for numeric features.

# Missing Values Check
missing=data.isna().sum()
missing

# Observation: There are 4 columns with missing data

# Checking percentage  missing values
missing_percent = (missing / len(data)) * 100
missing_df = pd.concat([missing, missing_percent], axis=1)
missing_df.columns = ['Missing Values', 'Percent']
print("\nColumns with Missing Values:")
display(missing_df[missing_df['Missing Values'] > 0])

# Observation: New financial ratios and profit metrics derived successfully.

#Handle Missing Data
# Separate numeric and categorical columns
numeric_cols = [
    'Revenue', 'COGS', 'Operating_Expenses','Depreciation_Amortization',
    'Change_in_Inventory','Accounts_Receivable', 'Accounts_Payable', 'Taxes_Paid',
    'CapEx', 'Asset_Sale_Proceeds', 'Investments_Bought',
    'Investments_Sold','Interest_Received',
    'Debt_Raised', 'Debt_Repaid', 'Interest_Paid',
    'Equity_Issued', 'Dividends_Paid', 'Net_Cash_Flow',
]
categorical_cols = ['Company_Name',  'Month']

# Check missing values
for col in categorical_cols:
    data[col].fillna('Unknown', inplace=True)
for col in numeric_cols:
    data[col].fillna(data[col].median(), inplace=True)

# Observation: Missing numeric values filled with median; categorical with 'Unknown'.

import pandas as pd

# Example: Assuming df is your DataFrame
# df = pd.read_csv('cashflow_data.csv')

# Calculate Operating Cash Flow (OCF)
data['Operating_Cash_Flow'] = (
    (data['Revenue'] - data['COGS'] - data['Operating_Expenses'])
    + data['Depreciation_Amortization']
    - (data['Change_in_Inventory'] + data['Accounts_Receivable'] - data['Accounts_Payable'])
    - data['Taxes_Paid']
)

# Calculate Investing Cash Flow (ICF)
data['Investing_Cash_Flow'] = (
    (-data['CapEx'])
    + data['Asset_Sale_Proceeds']
    - data['Investments_Bought']
    + data['Investments_Sold']
    + data['Interest_Received']
)

# Calculate Financing Cash Flow (FCF)
data['Financing_Cash_Flow'] = (
    data['Debt_Raised']
    - data['Debt_Repaid']
    - data['Interest_Paid']
    + data['Equity_Issued']
    - data['Dividends_Paid']
)

# Calculate Net Cash Flow
data['Cash_Flow'] = (
    data['Operating_Cash_Flow']
    + data['Investing_Cash_Flow']
    + data['Financing_Cash_Flow']
)

# Calculate Closing Cash
#data['Closing_Cash'] = data['Opening_Cash'] + data['Net_Cash_Flow']

# Display the final DataFrame
print(data[['Company_Name','Month','Operating_Cash_Flow','Investing_Cash_Flow','Financing_Cash_Flow','Cash_Flow']].head())

engineered_features = [ 'Operating_Cash_Flow', 'Investing_Cash_Flow', 'Financing_Cash_Flow']
numeric_cols.extend(engineered_features)

# Correlation heatmap
plt.figure(figsize=(15,8))
sns.heatmap(data[numeric_cols + ['Net_Cash_Flow']].corr(), annot=True, cmap='coolwarm')
plt.title("Correlation Heatmap")
plt.show()

# Observation: Reveals strong correlations between Revenue, Profits, and Net Cash Flow.

pairs = [
    ('Revenue', 'Operating_Cash_Flow'),
    ('COGS', 'Net_Cash_Flow'),
    ('Operating_Expenses', 'Net_Cash_Flow'),
    ('CapEx', 'Investing_Cash_Flow'),
    ('Debt_Raised', 'Financing_Cash_Flow')]

# Create scatter plots
for x, y in pairs:
    plt.figure(figsize=(6,4))
    sns.regplot(x=x, y=y, data=data, scatter_kws={'alpha':0.5}, line_kws={'color':'red'})
    plt.title(f"Linearity Check: {x} vs {y}")
    plt.show()

# Observation: Positive linear relation visible between revenue and cash flow.

# Boxplot before outlier treatment
plt.figure(figsize=(12,8))
sns.boxplot(data=data[numeric_cols], orient="h", color='lightblue')
plt.title("Boxplot of Numeric Features (Before Outlier Treatment)", fontsize=14)
plt.tight_layout()
plt.show()

# Observation: Multiple features show extreme outliers.

#Outlier Treatment (IQR Capping)
def cap_outliers_iqr(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    df[column] = np.where(df[column] < lower, lower,
                          np.where(df[column] > upper, upper, df[column]))
    return df

for col in numeric_cols:
    data = cap_outliers_iqr(data, col)
    print(f"{col} outliers capped.")

# Observation: Outliers reduced using IQR-based capping.

missing=data.isna().sum()
missing

#Outlier Visualization (After)
plt.figure(figsize=(12,8))
sns.boxplot(data=data[numeric_cols], orient='h')
plt.title("Boxplot of Numeric Features (After Outlier Treatment)")
plt.show()

# One-Hot Encoding
encoder = OneHotEncoder(drop='first', sparse_output=False)
encoded_cols = pd.DataFrame(encoder.fit_transform(data[categorical_cols]),
                            columns=encoder.get_feature_names_out(categorical_cols))
data_encoded = pd.concat([data.drop(columns=categorical_cols).reset_index(drop=True),
                          encoded_cols.reset_index(drop=True)], axis=1)

# Observation: One-hot encoding successfully created binary categorical features.



#Feature Scaling
scaler = StandardScaler()
data_encoded[numeric_cols] = scaler.fit_transform(data_encoded[numeric_cols])

# Observation: Numeric features standardized for model stability.

X = data_encoded.drop(columns=[
    'Net_Cash_Flow'])
y = data_encoded['Net_Cash_Flow']

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Observation: Data split into 80% train and 20% test sets.

print("Train Shape:", X_train.shape, y_train.shape)
print("Test Shape:", X_test.shape, y_test.shape)

# Model Evaluation Function
def evaluate_model(y_true, y_pred, model_name):
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)
    n_samples = len(y_true)
    n_features = X_train.shape[1]
    adj_r2 = 1 - (1 - r2) * (n_samples - 1) / (n_samples - n_features - 1)
    print(f"\n{model_name} Evaluation Metrics:")
    print(f"Mean_absolute_error: {mae:.4f}")
    print(f"Mean_squared_error: {mse:.4f}")
    print(f"RMSE: {rmse:.4f}")
    print(f"RÂ²: {r2:.4f}")
    print(f"Adjusted RÂ²: {adj_r2:.4f}")
    return mae,mse, rmse, r2, adj_r2

# 1. LINEAR REGRESSION MODEL
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

y_test_pred_lr = lr_model.predict(X_test)
print(y_test_pred_lr[:12])

# Train

mae_lr, mse_lr, rmse_lr, r2_lr, adj_r2_lr = evaluate_model(y_test, y_test_pred_lr, "Linear Regression")

# Test
y_test_pred_lr = lr_model.predict(X_test)
mae_test_lr, mse_test_lr, rmse_test_lr, r2_test_lr, adj_r2_test_lr = evaluate_model(y_test, y_test_pred_lr, "Linear Regression (Test)")

# 2. RANDOM FOREST REGRESSION
rf_model = RandomForestRegressor(n_estimators=200, random_state=42)
rf_model.fit(X_train, y_train)

# Train
y_train_pred_rf = rf_model.predict(X_train)
mae_train_rf, mse_train_rf, rmse_train_rf, r2_train_rf, adj_r2_train_rf = evaluate_model(y_train, y_train_pred_rf, "Random Forest Regression (Train)")

# Test
y_test_pred_rf = rf_model.predict(X_test)
mae_test_rf, mse_test_rf, rmse_test_rf, r2_test_rf, adj_r2_test_rf = evaluate_model(y_test, y_test_pred_rf, "Random Forest Regression (Test)")

xgb_model = XGBRegressor(
    n_estimators=300,
    learning_rate=0.05,
    max_depth=6,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)
xgb_model.fit(X_train, y_train)

y_train_pred_xgb = xgb_model.predict(X_train)
print(y_train_pred_xgb[:12])

# Train
mae_train_xgb, mse_train_xgb, rmse_train_xgb, r2_train_xgb, adj_r2_train_xgb = evaluate_model(y_train, y_train_pred_xgb, "XGBoost Regression (Train)")

# Test
y_test_pred_xgb = xgb_model.predict(X_test)
mae_test_xgb, mse_test_xgb, rmse_test_xgb, r2_test_xgb, adj_r2_test_xgb = evaluate_model(y_test, y_test_pred_xgb, "XGBoost Regression (Test)")

# ðŸ“ˆ Model Comparison Summary
# ----------------------------
results = pd.DataFrame({
    'Model': ['Linear Regression', 'Random Forest', 'XGBoost'],
    'MAE': [mae_test_lr, mae_test_rf, mae_test_xgb],
    'RMSE': [rmse_test_lr, rmse_test_rf, rmse_test_xgb],
    'RÂ²': [r2_test_lr, r2_test_rf, r2_test_xgb],
    'Adjusted RÂ²': [adj_r2_test_lr, adj_r2_test_rf, adj_r2_test_xgb]
})

print("\nModel Performance Summary:")
display(results.round(4))
# Observation: Model comparison table shows performance ranking.

# 10. Visualization
# --------------------------
plt.figure(figsize=(8, 5))
sns.barplot(x='Model', y='RÂ²', data=results, palette='viridis')
plt.title("Model Comparison Based on RÂ²")
plt.ylabel("RÂ² Score")
plt.show()

# Define 5-Fold cross-validation
kfold = KFold(n_splits=5, shuffle=True, random_state=42)

# Define a dictionary of models to evaluate
models = {
    "Linear Regression": lr_model,
    "Random Forest": rf_model,
    "XGBoost": xgb_model
}

# Evaluate models
results = []
for name, model in models.items():
    print(f"\nðŸ”¹ Evaluating {name} with 5-Fold Cross Validation...")

    # RÂ² scores across 5 folds
    r2_scores = cross_val_score(model, X, y, cv=kfold, scoring='r2')
    mae_scores = -cross_val_score(model, X, y, cv=kfold, scoring='neg_mean_absolute_error')
    rmse_scores = np.sqrt(-cross_val_score(model, X, y, cv=kfold, scoring='neg_mean_squared_error'))

    results.append({
        "Model": name,
        "Mean RÂ²": np.mean(r2_scores),
        "Std RÂ²": np.std(r2_scores),
        "Mean MAE": np.mean(mae_scores),
        "Mean RMSE": np.mean(rmse_scores)
    })

    print(f"RÂ² Scores: {r2_scores}")
    print(f"Average RÂ²: {np.mean(r2_scores):.4f} Â± {np.std(r2_scores):.4f}")
    print(f"Average MAE: {np.mean(mae_scores):.4f}")
    print(f"Average RMSE: {np.mean(rmse_scores):.4f}")

# Convert results to DataFrame
results_df = pd.DataFrame(results)
print("\nðŸ“Š Cross-Validation Results Summary:")
display(results_df.round(4))

# 11. Best Model Visualization
# --------------------------
best_model_name = results_df.loc[results_df['Mean RÂ²'].idxmax(), 'Model']

# Use the best performing model (XGBoost) directly
y_pred_best = xgb_model.predict(X_test)

plt.figure(figsize=(7, 5))
sns.scatterplot(x=y_test, y=y_pred_best, color='green', alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')
plt.title(f"Actual vs Predicted Net Cash Flow ({best_model_name})")
plt.xlabel("Actual")
plt.ylabel("Predicted")
plt.grid(True)
plt.show()